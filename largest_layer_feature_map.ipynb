{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "'3.9.5 (default, Aug 29 2021, 19:01:31) \\n[GCC 9.3.0]'"
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from PIL import Image\n",
    "from torchvision import transforms, models\n",
    "from ModelAnalysis import ModelStatsAggregator, ModelStatAnalyser\n",
    "from sys import version\n",
    "version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/sultan/.cache/torch/hub/NVIDIA_DeepLearningExamples_torchhub\n",
      "Using cache found in /home/sultan/.cache/torch/hub/pytorch_vision_v0.10.0\n",
      "Using cache found in /home/sultan/.cache/torch/hub/ultralytics_yolov5_master\n",
      "YOLOv5 ðŸš€ 2021-8-29 torch 1.9.0+cu102 CUDA:0 (GeForce RTX 2070 SUPER, 7979.1875MB)\n",
      "\n",
      "Fusing layers... \n",
      "Model Summary: 224 layers, 7266973 parameters, 0 gradients\n",
      "Adding AutoShape... \n",
      "Using cache found in /home/sultan/.cache/torch/hub/ultralytics_yolov5_master\n",
      "YOLOv5 ðŸš€ 2021-8-29 torch 1.9.0+cu102 CUDA:0 (GeForce RTX 2070 SUPER, 7979.1875MB)\n",
      "\n",
      "Fusing layers... \n",
      "Model Summary: 308 layers, 21356877 parameters, 0 gradients\n",
      "Adding AutoShape... \n",
      "Using cache found in /home/sultan/.cache/torch/hub/ultralytics_yolov5_master\n",
      "YOLOv5 ðŸš€ 2021-8-29 torch 1.9.0+cu102 CUDA:0 (GeForce RTX 2070 SUPER, 7979.1875MB)\n",
      "\n",
      "Fusing layers... \n",
      "Model Summary: 392 layers, 47025981 parameters, 0 gradients\n",
      "Adding AutoShape... \n",
      "Using cache found in /home/sultan/.cache/torch/hub/ultralytics_yolov5_master\n",
      "YOLOv5 ðŸš€ 2021-8-29 torch 1.9.0+cu102 CUDA:0 (GeForce RTX 2070 SUPER, 7979.1875MB)\n",
      "\n",
      "Fusing layers... \n",
      "Model Summary: 476 layers, 87730285 parameters, 0 gradients\n",
      "Adding AutoShape... \n"
     ]
    }
   ],
   "source": [
    "model_dict = {\n",
    "    'ssd': torch.hub.load('NVIDIA/DeepLearningExamples:torchhub', 'nvidia_ssd'),\n",
    "    'lenet': torch.hub.load('pytorch/vision:v0.10.0', 'googlenet', pretrained=True),\n",
    "    'yolov5s': torch.hub.load('ultralytics/yolov5', 'yolov5s', pretrained=True),\n",
    "    'yolov5m': torch.hub.load('ultralytics/yolov5', 'yolov5m', pretrained=True),\n",
    "    'yolov5l': torch.hub.load('ultralytics/yolov5', 'yolov5l', pretrained=True),\n",
    "    'yolov5x': torch.hub.load('ultralytics/yolov5', 'yolov5x', pretrained=True),\n",
    "    'alexnet': models.alexnet(pretrained=True, progress=True),\n",
    "    'vgg_11': models.vgg11(pretrained=True, progress=True),\n",
    "    'vgg_13': models.vgg13(pretrained=True, progress=True),\n",
    "    'vgg_16': models.vgg16(pretrained=True, progress=True),\n",
    "    'vgg_19': models.vgg19(pretrained=True, progress=True),\n",
    "    'vgg_11_bn': models.vgg11_bn(pretrained=True, progress=True),\n",
    "    'vgg_13_bn': models.vgg13_bn(pretrained=True, progress=True),\n",
    "    'vgg_16_bn': models.vgg16_bn(pretrained=True, progress=True),\n",
    "    'vgg_19_bn': models.vgg19_bn(pretrained=True, progress=True),\n",
    "    'resnet_18': models.resnet18(pretrained=True, progress=True),\n",
    "    'resnet_34': models.resnet34(pretrained=True, progress=True),\n",
    "    'resnet_50': models.resnet50(pretrained=True, progress=True),\n",
    "    'resnet_101': models.resnet101(pretrained=True, progress=True),\n",
    "    'resnet_152': models.resnet152(pretrained=True, progress=True),\n",
    "    'squeezenet_1_0': models.squeezenet1_1(pretrained=True, progress=True),\n",
    "    'squeezenet_1_1': models.squeezenet1_0(pretrained=True, progress=True),\n",
    "    'densenet_121': models.densenet121(pretrained=True, progress=True),\n",
    "    'densenet_169': models.densenet169(pretrained=True, progress=True),\n",
    "    'densenet_201': models.densenet201(pretrained=True, progress=True),\n",
    "    'densenet_161': models.densenet161(pretrained=True, progress=True),\n",
    "    'inception_v3': models.inception_v3(pretrained=True, progress=True),\n",
    "    'googlenet': models.googlenet(pretrained=True, progress=True),\n",
    "    'shufflenet_v2_x0_5': models.shufflenet_v2_x0_5(pretrained=True, progress=True),\n",
    "    'shufflenet_v2_x1_0': models.shufflenet_v2_x1_0(pretrained=True, progress=True),\n",
    "    'mobilenet_v2': models.mobilenet_v2(pretrained=True, progress=True),\n",
    "    'mobilenet_v3_large': models.mobilenet_v3_large(pretrained=True, progress=True),\n",
    "    'mobilenet_v3_small': models.mobilenet_v3_small(pretrained=True, progress=True),\n",
    "    'resnext_50_32x4d': models.resnext50_32x4d(pretrained=True, progress=True),\n",
    "    'resnext_101_32x8d': models.resnext101_32x8d(pretrained=True, progress=True),\n",
    "    'wide_resnet_50_2': models.wide_resnet50_2(pretrained=True, progress=True),\n",
    "    'wide_resnet_101_2': models.wide_resnet101_2(pretrained=True, progress=True),\n",
    "    'mnasnet0_5': models.mnasnet0_5(pretrained=True, progress=True),\n",
    "    'mnasnet1_0': models.mnasnet1_0(pretrained=True, progress=True),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/sultan/.cache/torch/hub/NVIDIA_DeepLearningExamples_torchhub\n"
     ]
    }
   ],
   "source": [
    "# prepare sample inputs\n",
    "import urllib\n",
    "url, filename = (\"https://github.com/pytorch/hub/raw/master/images/dog.jpg\", \"dog.jpg\")\n",
    "try: urllib.URLopener().retrieve(url, filename)\n",
    "except: urllib.request.urlretrieve(url, filename)\n",
    "\n",
    "input_image = Image.open(filename)\n",
    "preprocess = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "input_tensor = preprocess(input_image)\n",
    "input_batch = input_tensor.unsqueeze(0) # create a mini-batch as expected by the model\n",
    "\n",
    "uris = [\n",
    "    'http://images.cocodataset.org/val2017/000000397133.jpg'\n",
    "]\n",
    "utils = torch.hub.load('NVIDIA/DeepLearningExamples:torchhub', 'nvidia_ssd_processing_utils')\n",
    "\n",
    "inputs = [utils.prepare_input(uri) for uri in uris]\n",
    "ssd_input_batch = utils.prepare_tensor(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analysing ssd\n",
      "Analysing lenet\n",
      "Analysing yolov5s\n",
      "Analysing yolov5m\n",
      "Analysing yolov5l\n",
      "Analysing yolov5x\n",
      "Analysing alexnet\n",
      "Analysing vgg_11\n",
      "Analysing vgg_13\n",
      "Analysing vgg_16\n",
      "Analysing vgg_19\n",
      "Analysing vgg_11_bn\n",
      "Analysing vgg_13_bn\n",
      "Analysing vgg_16_bn\n",
      "Analysing vgg_19_bn\n",
      "Analysing resnet_18\n",
      "Analysing resnet_34\n",
      "Analysing resnet_50\n",
      "Analysing resnet_101\n",
      "Analysing resnet_152\n",
      "Analysing squeezenet_1_0\n",
      "Analysing squeezenet_1_1\n",
      "Analysing densenet_121\n",
      "Analysing densenet_169\n",
      "Analysing densenet_201\n",
      "Analysing densenet_161\n",
      "Analysing inception_v3\n",
      "Analysing googlenet\n",
      "Analysing shufflenet_v2_x0_5\n",
      "Analysing shufflenet_v2_x1_0\n",
      "Analysing mobilenet_v2\n",
      "Analysing mobilenet_v3_large\n",
      "Analysing mobilenet_v3_small\n",
      "Analysing resnext_50_32x4d\n",
      "Analysing resnext_101_32x8d\n",
      "Analysing wide_resnet_50_2\n",
      "Analysing wide_resnet_101_2\n",
      "Analysing mnasnet0_5\n",
      "Analysing mnasnet1_0\n"
     ]
    }
   ],
   "source": [
    "stats_dict, _ = ModelStatAnalyser.get_models_stats_dict(model_dict, input_batch, ssd_input_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "{'7': 0.011862396204033215,\n '1': 0.5776986951364176,\n '3': 0.39541320680110714,\n '5': 0.015025701858442072}"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ModelStatsAggregator.get_aggregate_kernel_stats_as_percentages(stats_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "{'7': Counter({'2': 17, '1': 13}),\n '1': Counter({'1': 1431, '2': 28}),\n '3': Counter({'1': 910, '2': 90}),\n '11': Counter({'4': 1}),\n '5': Counter({'1': 28, '2': 10})}"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ModelStatsAggregator.get_aggregate_stride_stats_per_kernel(stats_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "{'128': 392,\n '256': 334,\n '512': 261,\n '1024': 219,\n '192': 149,\n '64': 117,\n '160': 65,\n '96': 64,\n '48': 56,\n '320': 55,\n '384': 51,\n '24': 37,\n '768': 36,\n '3': 35,\n '640': 34,\n '32': 31,\n '576': 30,\n '116': 26,\n '16': 26,\n '2048': 25,\n '480': 25,\n '832': 21,\n '288': 21,\n '240': 20,\n '1280': 19,\n '960': 19,\n '72': 18,\n '80': 17,\n '1152': 14,\n '232': 14,\n '120': 14,\n '144': 14,\n '40': 13,\n '672': 13,\n '58': 11,\n '528': 10,\n '448': 8,\n '1536': 6,\n '224': 6,\n '352': 6,\n '416': 6,\n '864': 6,\n '896': 6,\n '928': 6,\n '992': 6,\n '1056': 6,\n '1248': 6,\n '704': 5,\n '736': 5,\n '800': 5,\n '1344': 5,\n '1440': 5,\n '1632': 5,\n '544': 4,\n '608': 4,\n '1088': 4,\n '1120': 4,\n '1184': 4,\n '1216': 4,\n '1728': 4,\n '184': 4,\n '112': 4,\n '12': 4,\n '1312': 3,\n '1376': 3,\n '1408': 3,\n '1472': 3,\n '1504': 3,\n '1568': 3,\n '1600': 3,\n '1824': 3,\n '1664': 2,\n '1696': 2,\n '1760': 2,\n '1792': 2,\n '336': 2,\n '432': 2,\n '624': 2,\n '720': 2,\n '1104': 2,\n '1200': 2,\n '1296': 2,\n '1392': 2,\n '1488': 2,\n '1584': 2,\n '1680': 2,\n '1776': 2,\n '1872': 2,\n '1920': 2,\n '1968': 2,\n '2016': 2,\n '2064': 2,\n '2112': 2,\n '168': 2,\n '8': 2,\n '200': 2,\n '88': 2,\n '2560': 1,\n '1856': 1,\n '1888': 1,\n '816': 1,\n '912': 1,\n '1008': 1,\n '2160': 1,\n '464': 1}"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ModelStatsAggregator.get_aggregate_in_channel_stats(stats_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "{'7': {'64': 15, '192': 7, '160': 4, '96': 2, '128': 2},\n '1': {'128': 328,\n  '1024': 174,\n  '256': 168,\n  '192': 134,\n  '512': 113,\n  '64': 64,\n  '160': 42,\n  '96': 41,\n  '48': 38,\n  '320': 33,\n  '2048': 31,\n  '24': 28,\n  '384': 26,\n  '32': 24,\n  '640': 18,\n  '116': 17,\n  '16': 16,\n  '80': 14,\n  '576': 14,\n  '40': 13,\n  '255': 12,\n  '240': 11,\n  '72': 10,\n  '144': 9,\n  '58': 9,\n  '232': 9,\n  '120': 9,\n  '960': 8,\n  '112': 6,\n  '1280': 6,\n  '480': 5,\n  '672': 4,\n  '288': 4,\n  '1152': 4,\n  '768': 3,\n  '1000': 2,\n  '448': 2,\n  '184': 2,\n  '168': 2,\n  '8': 2,\n  '896': 1,\n  '1056': 1,\n  '200': 1,\n  '88': 1},\n '3': {'32': 248,\n  '256': 156,\n  '512': 113,\n  '48': 95,\n  '128': 87,\n  '64': 58,\n  '1024': 33,\n  '320': 27,\n  '192': 25,\n  '96': 25,\n  '384': 20,\n  '160': 17,\n  '24': 12,\n  '640': 10,\n  '16': 9,\n  '116': 9,\n  '80': 5,\n  '232': 5,\n  '576': 5,\n  '58': 4,\n  '72': 4,\n  '324': 3,\n  '486': 3,\n  '288': 3,\n  '960': 3,\n  '2048': 3,\n  '208': 2,\n  '224': 2,\n  '144': 2,\n  '240': 2,\n  '184': 2,\n  '480': 2,\n  '768': 1,\n  '1280': 1,\n  '200': 1,\n  '672': 1,\n  '88': 1,\n  '1152': 1},\n '11': {'64': 1},\n '5': {'576': 6,\n  '120': 5,\n  '240': 5,\n  '72': 4,\n  '64': 3,\n  '1152': 3,\n  '960': 2,\n  '144': 2,\n  '288': 2,\n  '480': 2,\n  '192': 1,\n  '672': 1,\n  '96': 1,\n  '48': 1}}"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ModelStatsAggregator.get_aggregate_filter_stats_per_kernel(stats_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "{'128': 417,\n '256': 324,\n '32': 272,\n '512': 226,\n '1024': 207,\n '192': 167,\n '64': 141,\n '48': 134,\n '96': 69,\n '160': 63,\n '320': 60,\n '384': 46,\n '24': 40,\n '2048': 34,\n '640': 28,\n '116': 26,\n '16': 25,\n '576': 25,\n '80': 19,\n '240': 18,\n '72': 18,\n '232': 14,\n '120': 14,\n '40': 13,\n '144': 13,\n '58': 13,\n '960': 13,\n '255': 12,\n '480': 9,\n '288': 9,\n '1152': 8,\n '1280': 7,\n '112': 6,\n '672': 6,\n '768': 4,\n '184': 4,\n '324': 3,\n '486': 3,\n '1000': 2,\n '448': 2,\n '168': 2,\n '8': 2,\n '200': 2,\n '88': 2,\n '208': 2,\n '224': 2,\n '896': 1,\n '1056': 1}"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ModelStatsAggregator.get_aggregate_filter_stats(stats_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.5  ('.venv': venv)",
   "name": "python395jvsc74a57bd07ba5a8c11295bd31a650da7fd95bdbf05f90d3e784de664cc7b5246ae59e510d"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "metadata": {
   "interpreter": {
    "hash": "7ba5a8c11295bd31a650da7fd95bdbf05f90d3e784de664cc7b5246ae59e510d"
   }
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}